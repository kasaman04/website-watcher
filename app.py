import asyncio
import json
import logging
import hashlib
import os
import time
import weakref
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import List, Dict, Optional, Set
from logging.handlers import RotatingFileHandler
import httpx
import aiosmtplib
from fastapi import FastAPI, HTTPException, Request, Form
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, RedirectResponse
from fastapi.middleware.cors import CORSMiddleware
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from pydantic import BaseModel, ValidationError
import uvicorn
from dotenv import load_dotenv

# ãƒ­ã‚°è¨­å®š - ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ã
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ© (æœ€å¤§10MBã€5ã¤ã¾ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—)
file_handler = RotatingFileHandler(
    'watcher.log', 
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5,
    encoding='utf-8'
)
file_handler.setFormatter(log_formatter)

# ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)

# ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    handlers=[file_handler, console_handler]
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®š
limiter = Limiter(key_func=get_remote_address)
app = FastAPI(title="Website Watcher", description="é«˜ä¿¡é ¼æ€§ã‚µã‚¤ãƒˆæ›´æ–°ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ")
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# ç°¡å˜ãªèªè¨¼è¨­å®š
AUTH_PASSWORD = os.getenv("AUTH_PASSWORD", "1033")

# æ¥µã‚ã¦ã‚·ãƒ³ãƒ—ãƒ«ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆç’°å¢ƒå¤‰æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
logged_in_ips = set()  # ãƒ¡ãƒ¢ãƒªå†…ã‚»ãƒƒã‚·ãƒ§ãƒ³


# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
monitoring_task = None
sites_data = []
httpx_client = None
cache = {}
cache_ttl = {}
failed_sites: Set[str] = set()
metrics = {
    'total_checks': 0,
    'failed_checks': 0,
    'email_sent': 0,
    'email_failed': 0,
    'last_check_time': None,
    'uptime_start': datetime.now(),
    'circuit_breaker_active': 0
}

class Site(BaseModel):
    url: str
    email: str
    name: Optional[str] = ""

class CircuitBreaker:
    """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³å®Ÿè£…"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 300):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def call(self, func):
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "HALF_OPEN"
                logger.info("ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼: HALF_OPENçŠ¶æ…‹")
            else:
                raise Exception("ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼: OPENçŠ¶æ…‹")
        
        try:
            result = func()
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
                self.failure_count = 0
                logger.info("ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼: CLOSEDçŠ¶æ…‹ã«å¾©æ—§")
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = "OPEN"
                logger.warning(f"ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼: OPENçŠ¶æ…‹ ({self.failure_count}å›å¤±æ•—)")
                metrics['circuit_breaker_active'] += 1
            raise e

class AsyncEmailService:
    """éåŒæœŸãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ä»˜ãï¼‰"""
    
    def __init__(self):
        self.smtp_server = os.getenv("SMTP_SERVER", "smtp.gmail.com")
        self.smtp_port = int(os.getenv("SMTP_PORT", "587"))
        self.username = os.getenv("SMTP_USERNAME", "")
        self.password = os.getenv("SMTP_PASSWORD", "")
        self.from_email = os.getenv("FROM_EMAIL", "")
        self.circuit_breaker = CircuitBreaker(failure_threshold=5, timeout=300)
    
    async def send_email(self, to_email: str, subject: str, body: str) -> bool:
        """éåŒæœŸãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
        if not all([self.username, self.password, self.from_email]):
            logger.error("Gmailè¨­å®šãŒä¸å®Œå…¨ã§ã™")
            return False
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                await self._send_with_circuit_breaker(to_email, subject, body)
                logger.info(f"âœ… ãƒ¡ãƒ¼ãƒ«é€ä¿¡æˆåŠŸ: {to_email}")
                metrics['email_sent'] += 1
                return True
                
            except Exception as e:
                logger.error(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¤±æ•— (è©¦è¡Œ{attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
        
        metrics['email_failed'] += 1
        return False
    
    async def _send_with_circuit_breaker(self, to_email: str, subject: str, body: str):
        """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ä»˜ããƒ¡ãƒ¼ãƒ«é€ä¿¡"""
        def send_func():
            return asyncio.create_task(self._send_email_core(to_email, subject, body))
        
        task = self.circuit_breaker.call(send_func)
        await task
    
    async def _send_email_core(self, to_email: str, subject: str, body: str):
        """ã‚³ã‚¢ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ©Ÿèƒ½"""
        msg = MIMEMultipart()
        msg['From'] = self.from_email
        msg['To'] = to_email
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        await aiosmtplib.send(
            msg,
            hostname=self.smtp_server,
            port=self.smtp_port,
            start_tls=True,
            username=self.username,
            password=self.password,
            timeout=30
        )
    
    async def test_connection(self) -> bool:
        """SMTPæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            logger.info("Gmail SMTPæ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...")
            async with aiosmtplib.SMTP(hostname=self.smtp_server, port=self.smtp_port) as server:
                await server.starttls()
                await server.login(self.username, self.password)
            logger.info("âœ… Gmail SMTPæ¥ç¶šæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ Gmail SMTPæ¥ç¶šå¤±æ•—: {e}")
            return False

class AsyncSiteChecker:
    """éåŒæœŸã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, client: httpx.AsyncClient):
        self.client = client
        self.site_circuits = {}  # ã‚µã‚¤ãƒˆåˆ¥ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼
    
    async def get_site_hash(self, url: str, timeout: int = 10) -> Optional[str]:
        """éåŒæœŸã‚µã‚¤ãƒˆãƒãƒƒã‚·ãƒ¥å–å¾—"""
        if url not in self.site_circuits:
            self.site_circuits[url] = CircuitBreaker(failure_threshold=3, timeout=180)
        
        try:
            def check_func():
                return self._check_site_core(url, timeout)
            
            content_hash = await self.site_circuits[url].call(check_func)
            logger.info(f"âœ… ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯æˆåŠŸ: {url} (hash: {content_hash[:8]}...)")
            return content_hash
            
        except Exception as e:
            logger.error(f"âŒ ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯å¤±æ•—: {url} - {e}")
            metrics['failed_checks'] += 1
            return None
    
    async def _check_site_core(self, url: str, timeout: int) -> str:
        """ã‚³ã‚¢ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = await self.client.get(url, timeout=timeout, headers=headers)
        response.raise_for_status()
        
        content_hash = hashlib.md5(response.text.encode('utf-8')).hexdigest()
        metrics['total_checks'] += 1
        return content_hash

# ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
email_service = AsyncEmailService()
site_checker = None  # å¾Œã§åˆæœŸåŒ–

# ç°¡å˜ãªèªè¨¼é–¢æ•°
def get_client_ip(request: Request) -> str:
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIPã‚¢ãƒ‰ãƒ¬ã‚¹å–å¾—ï¼ˆRenderå¯¾å¿œï¼‰"""
    # Renderã®Proxyãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å„ªå…ˆ
    forwarded = request.headers.get("X-Forwarded-For")
    if forwarded:
        ip = forwarded.split(",")[0].strip()
        # æœ¬ç•ªç’°å¢ƒã§ã¯è©³ç´°ãƒ­ã‚°ã‚’æŠ‘åˆ¶
        if os.getenv("ENVIRONMENT") != "production":
            logger.info(f"ğŸŒ Client IP (X-Forwarded-For): {ip}")
        return ip
    
    # CF-Connecting-IP (Cloudflare)
    cf_ip = request.headers.get("CF-Connecting-IP")
    if cf_ip:
        if os.getenv("ENVIRONMENT") != "production":
            logger.info(f"ğŸŒ Client IP (CF): {cf_ip}")
        return cf_ip
    
    # ç›´æ¥æ¥ç¶š
    direct_ip = request.client.host if request.client else "unknown"
    if os.getenv("ENVIRONMENT") != "production":
        logger.info(f"ğŸŒ Client IP (direct): {direct_ip}")
    return direct_ip

def is_authenticated(request: Request) -> bool:
    """èªè¨¼ãƒã‚§ãƒƒã‚¯"""
    client_ip = get_client_ip(request)
    is_logged_in = client_ip in logged_in_ips
    
    # æœ¬ç•ªç’°å¢ƒã§ã¯ç°¡ç•¥ãƒ­ã‚°ã€é–‹ç™ºç’°å¢ƒã§ã¯è©³ç´°ãƒ­ã‚°
    if os.getenv("ENVIRONMENT") == "production":
        if not is_logged_in:
            logger.info(f"ğŸ”’ æœªèªè¨¼ã‚¢ã‚¯ã‚»ã‚¹ - IP: {client_ip}")
    else:
        logger.info(f"ğŸ” èªè¨¼ãƒã‚§ãƒƒã‚¯ - IP: {client_ip}, ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹: {is_logged_in}, ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(logged_in_ips)}")
    
    return is_logged_in

def require_auth(request: Request):
    """èªè¨¼å¿…é ˆãƒã‚§ãƒƒã‚¯"""
    if not is_authenticated(request):
        raise HTTPException(status_code=401, detail="èªè¨¼ãŒå¿…è¦ã§ã™")


def get_cached_data(key: str, ttl_seconds: int = 30):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    if key in cache and key in cache_ttl:
        if time.time() - cache_ttl[key] < ttl_seconds:
            return cache[key]
    return None

def set_cached_data(key: str, data):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿è¨­å®š"""
    cache[key] = data
    cache_ttl[key] = time.time()

def load_sites() -> List[Dict]:
    """ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆåŸå­æ€§ä¿è¨¼ï¼‰"""
    try:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cached = get_cached_data('sites_config')
        if cached:
            return cached
        
        # Render.comã®ãƒ‡ã‚£ã‚¹ã‚¯ãƒ‘ã‚¹ã‚’å„ªå…ˆ
        config_path = '/opt/render/project/data/config.json'
        if not os.path.exists(config_path):
            config_path = 'config.json'
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                sites = data.get('sites', [])
                set_cached_data('sites_config', sites)
                return sites
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    return []

def save_sites(sites: List[Dict]):
    """ã‚µã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆåŸå­æ€§ä¿è¨¼ï¼‰"""
    try:
        config = {
            'sites': sites, 
            'settings': {
                'check_interval': int(os.getenv('CHECK_INTERVAL', '300')), 
                'timeout': 10, 
                'max_retries': 3
            }
        }
        
        # Render.comã®ãƒ‡ã‚£ã‚¹ã‚¯ãƒ‘ã‚¹ã‚’å„ªå…ˆ
        config_path = '/opt/render/project/data/config.json'
        config_dir = os.path.dirname(config_path)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        if not os.path.exists(config_dir):
            try:
                os.makedirs(config_dir, exist_ok=True)
            except:
                config_path = 'config.json'
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ â†’ åŸå­çš„ãƒªãƒãƒ¼ãƒ 
        temp_file = config_path + '.tmp'
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        os.replace(temp_file, config_path)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        set_cached_data('sites_config', sites)
        logger.info("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")
        
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

async def check_all_sites():
    """å…¨ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰"""
    global sites_data
    
    sites_data = load_sites()
    if not sites_data:
        logger.info("ç›£è¦–å¯¾è±¡ã‚µã‚¤ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    logger.info(f"ğŸ” {len(sites_data)}ã‚µã‚¤ãƒˆã®ç›£è¦–ã‚’é–‹å§‹")
    metrics['last_check_time'] = datetime.now()
    
    # æœ€å¤§5ã‚µã‚¤ãƒˆä¸¦åˆ—å‡¦ç†
    semaphore = asyncio.Semaphore(5)
    tasks = []
    
    for site in sites_data:
        task = asyncio.create_task(check_single_site(site, semaphore))
        tasks.append(task)
    
    # å…¨ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯å®Œäº†ã‚’å¾…æ©Ÿ
    await asyncio.gather(*tasks, return_exceptions=True)
    
    # è¨­å®šä¿å­˜
    save_sites(sites_data)

async def check_single_site(site: Dict, semaphore: asyncio.Semaphore):
    """å˜ä¸€ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯"""
    async with semaphore:
        try:
            url = site['url']
            email = site['email']
            name = site.get('name', url)
            last_hash = site.get('hash', '')
            
            # ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯
            current_hash = await site_checker.get_site_hash(url)
            if not current_hash:
                return
            
            # åˆå›ãƒã‚§ãƒƒã‚¯
            if not last_hash:
                site['hash'] = current_hash
                site['last_check'] = datetime.now().isoformat()
                logger.info(f"ğŸ“ åˆå›ãƒãƒƒã‚·ãƒ¥è¨­å®š: {name}")
                return
            
            # å¤‰æ›´æ¤œçŸ¥
            if current_hash != last_hash:
                logger.info(f"ğŸš¨ å¤‰æ›´æ¤œçŸ¥: {name}")
                
                # ãƒ¡ãƒ¼ãƒ«é€ä¿¡
                subject = f"ğŸ”” ã‚µã‚¤ãƒˆæ›´æ–°é€šçŸ¥: {name}"
                body = f"""
ã‚µã‚¤ãƒˆãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸï¼

ã‚µã‚¤ãƒˆå: {name}
URL: {url}
æ›´æ–°æ¤œçŸ¥æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯ Website Watcher ã«ã‚ˆã‚Šè‡ªå‹•é€ä¿¡ã•ã‚Œã¾ã—ãŸã€‚
"""
                
                success = await email_service.send_email(email, subject, body)
                if success:
                    site['hash'] = current_hash
                    site['last_check'] = datetime.now().isoformat()
                    site['last_notified'] = datetime.now().isoformat()
                    logger.info(f"âœ… é€šçŸ¥å®Œäº†: {name} â†’ {email}")
                else:
                    logger.error(f"âŒ é€šçŸ¥å¤±æ•—: {name} â†’ {email}")
            else:
                site['last_check'] = datetime.now().isoformat()
                logger.info(f"ğŸ“ å¤‰æ›´ãªã—: {name}")
            
            # è² è·è»½æ¸›ç”¨å¾…æ©Ÿ
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.error(f"ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

async def monitoring_loop():
    """ç›£è¦–ãƒ«ãƒ¼ãƒ—ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãï¼‰"""
    logger.info("ğŸ”„ ç›£è¦–ãƒ«ãƒ¼ãƒ—é–‹å§‹")
    consecutive_failures = 0
    
    while True:
        try:
            await check_all_sites()
            consecutive_failures = 0  # æˆåŠŸæ™‚ãƒªã‚»ãƒƒãƒˆ
            
            check_interval = int(os.getenv("CHECK_INTERVAL", "300"))
            logger.info(f"â° {check_interval}ç§’å¾Œã«å†ãƒã‚§ãƒƒã‚¯")
            await asyncio.sleep(check_interval)
            
        except Exception as e:
            consecutive_failures += 1
            wait_time = min(60 * (2 ** consecutive_failures), 3600)  # æœ€å¤§1æ™‚é–“
            logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ (é€£ç¶š{consecutive_failures}å›): {e}")
            logger.info(f"â° {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤")
            await asyncio.sleep(wait_time)

async def task_monitor():
    """ã‚¿ã‚¹ã‚¯ç›£è¦–ï¼ˆè‡ªå‹•å¾©æ—§ï¼‰"""
    global monitoring_task
    
    while True:
        try:
            await asyncio.sleep(60)  # 1åˆ†ã”ã¨ãƒã‚§ãƒƒã‚¯
            
            if monitoring_task and monitoring_task.done():
                logger.warning("âš ï¸ ç›£è¦–ã‚¿ã‚¹ã‚¯ãŒåœæ­¢ã€‚å†èµ·å‹•ã—ã¾ã™")
                monitoring_task = asyncio.create_task(monitoring_loop())
                
        except Exception as e:
            logger.error(f"ã‚¿ã‚¹ã‚¯ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡
app_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(app_dir, "static")

# é™çš„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")
    logger.info(f"ğŸ“ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {static_dir}")
else:
    logger.error(f"âŒ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {static_dir}")

# FastAPI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®å‡¦ç†"""
    global monitoring_task, httpx_client, site_checker
    
    logger.info("ğŸš€ Website Watcher èµ·å‹•")
    
    # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    login_file = os.path.join(static_dir, "login.html")
    index_file = os.path.join(static_dir, "index.html")
    favicon_file = os.path.join(static_dir, "favicon.png")
    
    files_to_check = [
        ("login.html", login_file),
        ("index.html", index_file),
        ("favicon.png", favicon_file)
    ]
    
    for name, filepath in files_to_check:
        if os.path.exists(filepath):
            logger.info(f"âœ… {name}: å­˜åœ¨ç¢ºèª")
        else:
            logger.warning(f"âš ï¸ {name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {filepath}")
    
    # HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    httpx_client = httpx.AsyncClient(
        timeout=httpx.Timeout(30.0),
        limits=httpx.Limits(max_keepalive_connections=10, max_connections=20)
    )
    site_checker = AsyncSiteChecker(httpx_client)
    
    # è¨­å®šæ¤œè¨¼
    required_env = ['SMTP_USERNAME', 'SMTP_PASSWORD', 'FROM_EMAIL']
    missing_env = [env for env in required_env if not os.getenv(env)]
    if missing_env:
        logger.warning(f"âš ï¸ æœªè¨­å®šã®ç’°å¢ƒå¤‰æ•°: {missing_env}")
    
    # SMTPæ¥ç¶šãƒ†ã‚¹ãƒˆ
    if await email_service.test_connection():
        logger.info("âœ… ãƒ¡ãƒ¼ãƒ«è¨­å®šç¢ºèªå®Œäº†")
    else:
        logger.warning("âš ï¸ ãƒ¡ãƒ¼ãƒ«è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
    
    # èªè¨¼æƒ…å ±ç¢ºèª
    # èªè¨¼æƒ…å ±ã®ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ¬ç•ªã§ã¯ç°¡ç•¥åŒ–ï¼‰
    if os.getenv("ENVIRONMENT") == "production":
        logger.info("ğŸ”‘ èªè¨¼ã‚·ã‚¹ãƒ†ãƒ : æœ‰åŠ¹")
    else:
        logger.info(f"ğŸ”‘ èªè¨¼è¨­å®š: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰={'*' * len(AUTH_PASSWORD)}")
        logger.info(f"ğŸ“Š ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(logged_in_ips)}")
    
    # ç›£è¦–ã‚¿ã‚¹ã‚¯é–‹å§‹
    monitoring_task = asyncio.create_task(monitoring_loop())
    asyncio.create_task(task_monitor())

@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã®å‡¦ç†"""
    global monitoring_task, httpx_client
    
    if monitoring_task:
        monitoring_task.cancel()
        try:
            await monitoring_task
        except asyncio.CancelledError:
            pass
    
    if httpx_client:
        await httpx_client.aclose()
    
    logger.info("ğŸ‘‹ Website Watcher çµ‚äº†")


# èªè¨¼ãƒ«ãƒ¼ãƒˆ
@app.get("/login", response_class=HTMLResponse)
async def login_page():
    """ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    login_file = os.path.join(static_dir, "login.html")
    logger.info(f"ğŸ“„ ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸è¦æ±‚ - ãƒ•ã‚¡ã‚¤ãƒ«: {login_file}")
    
    if not os.path.exists(login_file):
        logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {login_file}")
        raise HTTPException(status_code=404, detail="Login page not found")
    
    return FileResponse(login_file)

@app.post("/login")
async def login(request: Request, password: str = Form(...)):
    """ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†"""
    client_ip = get_client_ip(request)
    
    # æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æ–‡å­—æ•°ã‚’éè¡¨ç¤º
    if os.getenv("ENVIRONMENT") == "production":
        logger.info(f"ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œ - IP: {client_ip}")
    else:
        logger.info(f"ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œ - IP: {client_ip}, ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: {'*' * len(password)}")
    
    if password == AUTH_PASSWORD:
        logged_in_ips.add(client_ip)
        logger.info(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ - IP: {client_ip}")
        return RedirectResponse(url="/", status_code=303)
    else:
        logger.warning(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•— - IP: {client_ip}")
        return RedirectResponse(url="/login?error=1", status_code=303)

@app.get("/logout")
async def logout(request: Request):
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"""
    client_ip = get_client_ip(request)
    was_logged_in = client_ip in logged_in_ips
    logged_in_ips.discard(client_ip)
    
    if os.getenv("ENVIRONMENT") == "production":
        logger.info(f"ğŸ˜ª ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ - IP: {client_ip}")
    else:
        logger.info(f"ğŸ˜ª ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ - IP: {client_ip}, ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹: {was_logged_in}, ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(logged_in_ips)}")
    
    return RedirectResponse(url="/login", status_code=303)

@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ï¼ˆèªè¨¼å¿…é ˆï¼‰"""
    client_ip = get_client_ip(request)
    
    # æœ¬ç•ªç’°å¢ƒã§ã¯ç°¡ç•¥ãƒ­ã‚°
    if os.getenv("ENVIRONMENT") != "production":
        logger.info(f"ğŸ  ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸è¦æ±‚ - IP: {client_ip}")
    
    if not is_authenticated(request):
        if os.getenv("ENVIRONMENT") != "production":
            logger.info(f"ğŸ”’ æœªèªè¨¼ã‚¢ã‚¯ã‚»ã‚¹ - ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ")
        return RedirectResponse(url="/login", status_code=303)
    
    index_file = os.path.join(static_dir, "index.html")
    if not os.path.exists(index_file):
        logger.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {index_file}")
        raise HTTPException(status_code=404, detail="Index page not found")
    
    return FileResponse(index_file)

# ãƒ•ã‚¡ãƒ“ã‚³ãƒ³é…ä¿¡
@app.get("/favicon.ico")
@app.get("/favicon.png")
async def favicon():
    """ãƒ•ã‚¡ãƒ“ã‚³ãƒ³é…ä¿¡"""
    favicon_file = os.path.join(static_dir, "favicon.png")
    if os.path.exists(favicon_file):
        return FileResponse(favicon_file, media_type="image/png")
    else:
        logger.warning("âš ï¸ ãƒ•ã‚¡ãƒ“ã‚³ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        raise HTTPException(status_code=404, detail="Favicon not found")

# ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/debug/auth")
async def debug_auth(request: Request):
    """èªè¨¼çŠ¶æ…‹ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯åˆ¶é™ã‚ã‚Šï¼‰"""
    client_ip = get_client_ip(request)
    is_auth = is_authenticated(request)
    
    # æœ¬ç•ªç’°å¢ƒã§ã¯æ©Ÿå¯†æƒ…å ±ã‚’éè¡¨ç¤º
    if os.getenv("ENVIRONMENT") == "production":
        return {
            "client_ip": client_ip,
            "is_authenticated": is_auth,
            "session_count": len(logged_in_ips),
            "auth_status": "enabled",
            "environment": "production"
        }
    
    # é–‹ç™ºç’°å¢ƒã§ã¯è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    return {
        "client_ip": client_ip,
        "is_authenticated": is_auth,
        "logged_in_ips": list(logged_in_ips),
        "session_count": len(logged_in_ips),
        "auth_password_set": bool(AUTH_PASSWORD),
        "headers": dict(request.headers)
    }

@app.get("/api/health")
@limiter.limit("60/minute")
async def health_check(request: Request):
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    uptime = datetime.now() - metrics['uptime_start']
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": int(uptime.total_seconds()),
        "monitoring_active": monitoring_task and not monitoring_task.done(),
        "sites_count": len(load_sites()),
        "circuit_breakers_active": metrics['circuit_breaker_active']
    }

@app.get("/api/metrics")
@limiter.limit("30/minute")
async def get_metrics(request: Request):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
    return {
        "metrics": metrics,
        "uptime": str(datetime.now() - metrics['uptime_start']),
        "cache_size": len(cache)
    }

@app.get("/api/sites")
@limiter.limit("120/minute")
async def get_sites(request: Request):
    """ã‚µã‚¤ãƒˆä¸€è¦§å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    require_auth(request)
    sites = load_sites()
    return {"sites": sites}

@app.post("/api/sites")
@limiter.limit("10/minute")
async def add_site(site: Site, request: Request):
    """ã‚µã‚¤ãƒˆè¿½åŠ """
    require_auth(request)
    sites = load_sites()
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    for existing_site in sites:
        if existing_site['url'] == site.url:
            raise HTTPException(status_code=400, detail="ã“ã®URLã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™")
    
    # URLæ¤œè¨¼
    if not site.url.startswith(('http://', 'https://')):
        raise HTTPException(status_code=400, detail="æœ‰åŠ¹ãªURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    # æ–°ã‚µã‚¤ãƒˆè¿½åŠ 
    new_site = {
        "url": site.url,
        "email": site.email,
        "name": site.name or site.url,
        "hash": "",
        "created_at": datetime.now().isoformat()
    }
    
    sites.append(new_site)
    save_sites(sites)
    
    logger.info(f"ğŸ“ æ–°ã‚µã‚¤ãƒˆç™»éŒ²: {site.name or site.url}")
    return {"message": "ã‚µã‚¤ãƒˆã‚’ç™»éŒ²ã—ã¾ã—ãŸ", "site": new_site}

@app.delete("/api/sites/{site_index}")
@limiter.limit("10/minute")
async def delete_site(site_index: int, request: Request):
    """ã‚µã‚¤ãƒˆå‰Šé™¤"""
    require_auth(request)
    sites = load_sites()
    
    if 0 <= site_index < len(sites):
        deleted_site = sites.pop(site_index)
        save_sites(sites)
        logger.info(f"ğŸ—‘ï¸ ã‚µã‚¤ãƒˆå‰Šé™¤: {deleted_site.get('name', deleted_site['url'])}")
        return {"message": "ã‚µã‚¤ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ"}
    else:
        raise HTTPException(status_code=404, detail="ã‚µã‚¤ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

@app.post("/api/test-email")
@limiter.limit("5/minute")
async def test_email(email_data: dict, request: Request):
    """ãƒ†ã‚¹ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
    to_email = email_data.get("email")
    if not to_email:
        raise HTTPException(status_code=400, detail="ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒå¿…è¦ã§ã™")
    
    subject = "ğŸ“§ Website Watcher ãƒ†ã‚¹ãƒˆãƒ¡ãƒ¼ãƒ«"
    body = f"""
ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯ Website Watcher ã®ãƒ†ã‚¹ãƒˆé€ä¿¡ã§ã™ã€‚

é€ä¿¡æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ã“ã®ãƒ¡ãƒ¼ãƒ«ãŒå±Šã„ã¦ã„ã‚Œã°ã€ãƒ¡ãƒ¼ãƒ«è¨­å®šã¯æ­£å¸¸ã§ã™ã€‚
"""
    
    success = await email_service.send_email(to_email, subject, body)
    if success:
        return {"message": "ãƒ†ã‚¹ãƒˆãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ã¾ã—ãŸ"}
    else:
        raise HTTPException(status_code=500, detail="ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")

@app.post("/api/check-now")
@limiter.limit("3/minute")
async def check_now(request: Request):
    """æ‰‹å‹•ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
    require_auth(request)
    logger.info("ğŸ” æ‰‹å‹•ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ")
    await check_all_sites()
    return {"message": "ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ"}

# ç·Šæ€¥ãƒ­ã‚°ã‚¤ãƒ³ç”¨ï¼ˆãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã¿ï¼‰
@app.post("/emergency-login")
async def emergency_login(request: Request):
    """ç·Šæ€¥ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    # æœ¬ç•ªç’°å¢ƒã§ã¯ç„¡åŠ¹
    if os.getenv("ENVIRONMENT") == "production":
        logger.warning(f"âš ï¸ æœ¬ç•ªç’°å¢ƒã§ç·Šæ€¥ãƒ­ã‚°ã‚¤ãƒ³ã®è©¦è¡Œã‚’æ¤œçŸ¥ - IP: {get_client_ip(request)}")
        raise HTTPException(status_code=404, detail="Not found")
    
    client_ip = get_client_ip(request)
    logged_in_ips.add(client_ip)
    logger.info(f"ğŸ†˜ ç·Šæ€¥ãƒ­ã‚°ã‚¤ãƒ³ - IP: {client_ip}")
    
    return {
        "message": "ç·Šæ€¥ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ",
        "client_ip": client_ip,
        "session_count": len(logged_in_ips)
    }

if __name__ == "__main__":
    port = int(os.getenv("PORT", "8888"))
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")